{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boost guided example\n",
    "\n",
    "Having walked through gradient boost by hand, now let's try it with SKlearn.  We'll still use the European Social Survey Data, but now with a categorical outcome: Whether or not someone lives with a partner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv((\n",
    "    \"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "    \"master/ESS_practice_data/ESSdata_Thinkful.csv\")).dropna()\n",
    "\n",
    "# Definine outcome and predictors.\n",
    "# Set our outcome to 0 and 1.\n",
    "y = df['partner'] - 1\n",
    "X = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'idno'])]\n",
    "\n",
    "# Make the categorical variable 'country' into dummies.\n",
    "X = pd.concat([X, pd.get_dummies(df['cntry'])], axis=1)\n",
    "\n",
    "# Create training and test sets.\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "\n",
    "# Put 90% of the data in the training set.\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "X_test, y_test = X[offset:], y[offset:]\n",
    "\n",
    "#print(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're now working with a binary outcome, we've switched to a classifier.  Now our loss function can't be the residuals.  Our options are \"deviance\", or \"exponential\".  Deviance is used for logistic regression, and we'll try that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0     0.0   1.0   All\n",
      "partner                  \n",
      "0.0      4167   341  4508\n",
      "1.0      1291  1533  2824\n",
      "All      5458  1874  7332\n",
      "Training set accuracy:\n",
      "Percent Type I errors: 0.04650845608292417\n",
      "Percent Type II errors: 0.17607746863066012\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.06257668711656442\n",
      "Percent Type II errors: 0.18527607361963191\n"
     ]
    }
   ],
   "source": [
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance'}\n",
    "#**params\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "print(table_train)\n",
    "\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0     0.0   1.0   All\n",
      "partner                  \n",
      "0.0      4274   234  4508\n",
      "1.0      1093  1731  2824\n",
      "All      5367  1965  7332\n",
      "Training set accuracy:\n",
      "Percent Type I errors: 0.031914893617021274\n",
      "Percent Type II errors: 0.14907255864702673\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.07116564417177915\n",
      "Percent Type II errors: 0.18159509202453988\n"
     ]
    }
   ],
   "source": [
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'exponential'}\n",
    "#**params\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "print(table_train)\n",
    "\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike decision trees, gradient boost solutions are not terribly easy to interpret on the surface.  But they aren't quite a black box.  We can get a measure of how important various features are by counting how many times a feature is used over the course of many decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "138.61266983830976\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = clf.feature_importances_\n",
    "print(feature_importance.sum())\n",
    "\n",
    "\n",
    "\n",
    "# Make importances relative to max importance.\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "print(feature_importance.sum())\n",
    "\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that age and happiness are the most important features in predicting whether or not someone lives with a partner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### DRILL: Improve this gradient boost model\n",
    "\n",
    "While this model is already doing alright, we've seen from the Type I and Type II error rates that there is definitely room for improvement.  Your task is to see how low you can get the error rates to go in the test set, based on your model in the training set.  Strategies you might use include:\n",
    "\n",
    "* Creating new features\n",
    "* Applying more overfitting-prevention strategies like subsampling\n",
    "* More iterations\n",
    "* Trying a different loss function\n",
    "* Changing the structure of the weak learner: Allowing more leaves in the tree, or other modifications\n",
    "\n",
    "Have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'tvtot', 'ppltrst', 'pplfair', 'pplhlp', 'happy', 'sclmeet',\n",
       "       'sclact', 'gndr', 'agea'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wscott\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\users\\wscott\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Make the categorical variable 'country' into dummies.\n",
    "X['agea_happy'] = X['agea'] * X['happy']\n",
    "X['agea_gndr'] = X['agea'] * X['gndr']\n",
    "X['agea_sclmeet'] = X['agea'] * X['sclmeet']\n",
    "X['happy_gndr'] = X['happy'] * X['gndr']\n",
    "X['happy_sclmeet'] = X['happy'] * X['sclmeet']\n",
    "\n",
    "\n",
    "# Create training and test sets.\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "\n",
    "# Put 90% of the data in the training set.\n",
    "X_train2, y_train2 = X[:offset], y[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "X_test2, y_test2 = X[offset:], y[offset:]\n",
    "\n",
    "#print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.04159847244953628\n",
      "Percent Type II errors: 0.15671031096563012\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.09202453987730061\n",
      "Percent Type II errors: 0.18404907975460122\n",
      "Total Error: 0.27607361963190186\n"
     ]
    }
   ],
   "source": [
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "params2 = {'n_estimators': 1000,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance',\n",
    "          'subsample' : 0.5}\n",
    "\n",
    "         #'min_samples_leaf' : 5}\n",
    "#**params\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf2 = ensemble.GradientBoostingClassifier(**params2)\n",
    "clf2.fit(X_train2, y_train2)\n",
    "\n",
    "predict_train2 = clf2.predict(X_train2)\n",
    "predict_test2 = clf2.predict(X_test2)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train2 = pd.crosstab(y_train2, predict_train2, margins=True)\n",
    "table_test2 = pd.crosstab(y_test2, predict_test2, margins=True)\n",
    "\n",
    "#print(table_train)\n",
    "\n",
    "\n",
    "train_tI_errors2 = table_train2.loc[0.0,1.0] / table_train2.loc['All','All']\n",
    "train_tII_errors2 = table_train2.loc[1.0,0.0] / table_train2.loc['All','All']\n",
    "\n",
    "test_tI_errors2 = table_test2.loc[0.0,1.0]/table_test2.loc['All','All']\n",
    "test_tII_errors2 = table_test2.loc[1.0,0.0]/table_test2.loc['All','All']\n",
    "test_All_errors2 = (table_test2.loc[1.0,0.0] + table_test2.loc[0.0,1.0]) /table_test2.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors2, train_tII_errors2, test_tI_errors2, test_tII_errors2))\n",
    "\n",
    "\n",
    "print('Total Error: {}'.format(test_All_errors2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "313.62306756016125\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance2 = clf2.feature_importances_\n",
    "print(feature_importance2.sum())\n",
    "\n",
    "\n",
    "\n",
    "# Make importances relative to max importance.\n",
    "feature_importance2 = 100.0 * (feature_importance2 / feature_importance2.max())\n",
    "print(feature_importance2.sum())\n",
    "\n",
    "sorted_idx2 = np.argsort(feature_importance2)\n",
    "pos = np.arange(sorted_idx2.shape[0]) + .5\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(pos, feature_importance2[sorted_idx2], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_idx2])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>tvtot</th>\n",
       "      <th>ppltrst</th>\n",
       "      <th>pplfair</th>\n",
       "      <th>pplhlp</th>\n",
       "      <th>happy</th>\n",
       "      <th>sclmeet</th>\n",
       "      <th>sclact</th>\n",
       "      <th>gndr</th>\n",
       "      <th>agea</th>\n",
       "      <th>agea_happy</th>\n",
       "      <th>agea_gndr</th>\n",
       "      <th>agea_sclmeet</th>\n",
       "      <th>happy_gndr</th>\n",
       "      <th>happy_sclmeet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.031596</td>\n",
       "      <td>-0.001600</td>\n",
       "      <td>0.004283</td>\n",
       "      <td>-0.032901</td>\n",
       "      <td>-0.013378</td>\n",
       "      <td>-0.028502</td>\n",
       "      <td>0.012150</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>-0.003520</td>\n",
       "      <td>-0.009733</td>\n",
       "      <td>-0.002965</td>\n",
       "      <td>-0.012521</td>\n",
       "      <td>-0.008215</td>\n",
       "      <td>-0.029354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tvtot</th>\n",
       "      <td>-0.031596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.142422</td>\n",
       "      <td>-0.119277</td>\n",
       "      <td>-0.069080</td>\n",
       "      <td>-0.118598</td>\n",
       "      <td>-0.078864</td>\n",
       "      <td>-0.092375</td>\n",
       "      <td>0.017922</td>\n",
       "      <td>0.257674</td>\n",
       "      <td>0.159138</td>\n",
       "      <td>0.198974</td>\n",
       "      <td>0.173123</td>\n",
       "      <td>-0.055287</td>\n",
       "      <td>-0.125004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppltrst</th>\n",
       "      <td>-0.001600</td>\n",
       "      <td>-0.142422</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.597506</td>\n",
       "      <td>0.459250</td>\n",
       "      <td>0.231533</td>\n",
       "      <td>0.122555</td>\n",
       "      <td>0.137491</td>\n",
       "      <td>-0.029921</td>\n",
       "      <td>-0.029412</td>\n",
       "      <td>0.093452</td>\n",
       "      <td>-0.041378</td>\n",
       "      <td>0.049429</td>\n",
       "      <td>0.107068</td>\n",
       "      <td>0.218143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pplfair</th>\n",
       "      <td>0.004283</td>\n",
       "      <td>-0.119277</td>\n",
       "      <td>0.597506</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.480931</td>\n",
       "      <td>0.247755</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>0.128808</td>\n",
       "      <td>0.022251</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0.142029</td>\n",
       "      <td>0.024530</td>\n",
       "      <td>0.072515</td>\n",
       "      <td>0.161255</td>\n",
       "      <td>0.203492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pplhlp</th>\n",
       "      <td>-0.032901</td>\n",
       "      <td>-0.069080</td>\n",
       "      <td>0.459250</td>\n",
       "      <td>0.480931</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.215323</td>\n",
       "      <td>0.080489</td>\n",
       "      <td>0.092673</td>\n",
       "      <td>0.042046</td>\n",
       "      <td>0.040351</td>\n",
       "      <td>0.146244</td>\n",
       "      <td>0.054497</td>\n",
       "      <td>0.084799</td>\n",
       "      <td>0.159035</td>\n",
       "      <td>0.177702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy</th>\n",
       "      <td>-0.013378</td>\n",
       "      <td>-0.118598</td>\n",
       "      <td>0.231533</td>\n",
       "      <td>0.247755</td>\n",
       "      <td>0.215323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.182944</td>\n",
       "      <td>0.192030</td>\n",
       "      <td>-0.022413</td>\n",
       "      <td>-0.042970</td>\n",
       "      <td>0.473904</td>\n",
       "      <td>-0.050481</td>\n",
       "      <td>0.073647</td>\n",
       "      <td>0.542478</td>\n",
       "      <td>0.692849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sclmeet</th>\n",
       "      <td>-0.028502</td>\n",
       "      <td>-0.078864</td>\n",
       "      <td>0.122555</td>\n",
       "      <td>0.096501</td>\n",
       "      <td>0.080489</td>\n",
       "      <td>0.182944</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.283319</td>\n",
       "      <td>0.009533</td>\n",
       "      <td>-0.194443</td>\n",
       "      <td>-0.075821</td>\n",
       "      <td>-0.127598</td>\n",
       "      <td>0.454794</td>\n",
       "      <td>0.113899</td>\n",
       "      <td>0.811592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sclact</th>\n",
       "      <td>0.012150</td>\n",
       "      <td>-0.092375</td>\n",
       "      <td>0.137491</td>\n",
       "      <td>0.128808</td>\n",
       "      <td>0.092673</td>\n",
       "      <td>0.192030</td>\n",
       "      <td>0.283319</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.031648</td>\n",
       "      <td>-0.059442</td>\n",
       "      <td>0.053886</td>\n",
       "      <td>-0.060063</td>\n",
       "      <td>0.123117</td>\n",
       "      <td>0.080131</td>\n",
       "      <td>0.308633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gndr</th>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.017922</td>\n",
       "      <td>-0.029921</td>\n",
       "      <td>0.022251</td>\n",
       "      <td>0.042046</td>\n",
       "      <td>-0.022413</td>\n",
       "      <td>0.009533</td>\n",
       "      <td>-0.031648</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020598</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>0.640597</td>\n",
       "      <td>0.030442</td>\n",
       "      <td>0.807616</td>\n",
       "      <td>-0.001063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agea</th>\n",
       "      <td>-0.003520</td>\n",
       "      <td>0.257674</td>\n",
       "      <td>-0.029412</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0.040351</td>\n",
       "      <td>-0.042970</td>\n",
       "      <td>-0.194443</td>\n",
       "      <td>-0.059442</td>\n",
       "      <td>0.020598</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.838211</td>\n",
       "      <td>0.741659</td>\n",
       "      <td>0.756282</td>\n",
       "      <td>-0.010638</td>\n",
       "      <td>-0.168050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agea_happy</th>\n",
       "      <td>-0.009733</td>\n",
       "      <td>0.159138</td>\n",
       "      <td>0.093452</td>\n",
       "      <td>0.142029</td>\n",
       "      <td>0.146244</td>\n",
       "      <td>0.473904</td>\n",
       "      <td>-0.075821</td>\n",
       "      <td>0.053886</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>0.838211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.607298</td>\n",
       "      <td>0.694645</td>\n",
       "      <td>0.266550</td>\n",
       "      <td>0.202723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agea_gndr</th>\n",
       "      <td>-0.002965</td>\n",
       "      <td>0.198974</td>\n",
       "      <td>-0.041378</td>\n",
       "      <td>0.024530</td>\n",
       "      <td>0.054497</td>\n",
       "      <td>-0.050481</td>\n",
       "      <td>-0.127598</td>\n",
       "      <td>-0.060063</td>\n",
       "      <td>0.640597</td>\n",
       "      <td>0.741659</td>\n",
       "      <td>0.607298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.574744</td>\n",
       "      <td>0.492776</td>\n",
       "      <td>-0.120401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agea_sclmeet</th>\n",
       "      <td>-0.012521</td>\n",
       "      <td>0.173123</td>\n",
       "      <td>0.049429</td>\n",
       "      <td>0.072515</td>\n",
       "      <td>0.084799</td>\n",
       "      <td>0.073647</td>\n",
       "      <td>0.454794</td>\n",
       "      <td>0.123117</td>\n",
       "      <td>0.030442</td>\n",
       "      <td>0.756282</td>\n",
       "      <td>0.694645</td>\n",
       "      <td>0.574744</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.065242</td>\n",
       "      <td>0.356296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy_gndr</th>\n",
       "      <td>-0.008215</td>\n",
       "      <td>-0.055287</td>\n",
       "      <td>0.107068</td>\n",
       "      <td>0.161255</td>\n",
       "      <td>0.159035</td>\n",
       "      <td>0.542478</td>\n",
       "      <td>0.113899</td>\n",
       "      <td>0.080131</td>\n",
       "      <td>0.807616</td>\n",
       "      <td>-0.010638</td>\n",
       "      <td>0.266550</td>\n",
       "      <td>0.492776</td>\n",
       "      <td>0.065242</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.388697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy_sclmeet</th>\n",
       "      <td>-0.029354</td>\n",
       "      <td>-0.125004</td>\n",
       "      <td>0.218143</td>\n",
       "      <td>0.203492</td>\n",
       "      <td>0.177702</td>\n",
       "      <td>0.692849</td>\n",
       "      <td>0.811592</td>\n",
       "      <td>0.308633</td>\n",
       "      <td>-0.001063</td>\n",
       "      <td>-0.168050</td>\n",
       "      <td>0.202723</td>\n",
       "      <td>-0.120401</td>\n",
       "      <td>0.356296</td>\n",
       "      <td>0.388697</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   year     tvtot   ppltrst   pplfair    pplhlp     happy  \\\n",
       "year           1.000000 -0.031596 -0.001600  0.004283 -0.032901 -0.013378   \n",
       "tvtot         -0.031596  1.000000 -0.142422 -0.119277 -0.069080 -0.118598   \n",
       "ppltrst       -0.001600 -0.142422  1.000000  0.597506  0.459250  0.231533   \n",
       "pplfair        0.004283 -0.119277  0.597506  1.000000  0.480931  0.247755   \n",
       "pplhlp        -0.032901 -0.069080  0.459250  0.480931  1.000000  0.215323   \n",
       "happy         -0.013378 -0.118598  0.231533  0.247755  0.215323  1.000000   \n",
       "sclmeet       -0.028502 -0.078864  0.122555  0.096501  0.080489  0.182944   \n",
       "sclact         0.012150 -0.092375  0.137491  0.128808  0.092673  0.192030   \n",
       "gndr           0.001355  0.017922 -0.029921  0.022251  0.042046 -0.022413   \n",
       "agea          -0.003520  0.257674 -0.029412  0.014724  0.040351 -0.042970   \n",
       "agea_happy    -0.009733  0.159138  0.093452  0.142029  0.146244  0.473904   \n",
       "agea_gndr     -0.002965  0.198974 -0.041378  0.024530  0.054497 -0.050481   \n",
       "agea_sclmeet  -0.012521  0.173123  0.049429  0.072515  0.084799  0.073647   \n",
       "happy_gndr    -0.008215 -0.055287  0.107068  0.161255  0.159035  0.542478   \n",
       "happy_sclmeet -0.029354 -0.125004  0.218143  0.203492  0.177702  0.692849   \n",
       "\n",
       "                sclmeet    sclact      gndr      agea  agea_happy  agea_gndr  \\\n",
       "year          -0.028502  0.012150  0.001355 -0.003520   -0.009733  -0.002965   \n",
       "tvtot         -0.078864 -0.092375  0.017922  0.257674    0.159138   0.198974   \n",
       "ppltrst        0.122555  0.137491 -0.029921 -0.029412    0.093452  -0.041378   \n",
       "pplfair        0.096501  0.128808  0.022251  0.014724    0.142029   0.024530   \n",
       "pplhlp         0.080489  0.092673  0.042046  0.040351    0.146244   0.054497   \n",
       "happy          0.182944  0.192030 -0.022413 -0.042970    0.473904  -0.050481   \n",
       "sclmeet        1.000000  0.283319  0.009533 -0.194443   -0.075821  -0.127598   \n",
       "sclact         0.283319  1.000000 -0.031648 -0.059442    0.053886  -0.060063   \n",
       "gndr           0.009533 -0.031648  1.000000  0.020598    0.002397   0.640597   \n",
       "agea          -0.194443 -0.059442  0.020598  1.000000    0.838211   0.741659   \n",
       "agea_happy    -0.075821  0.053886  0.002397  0.838211    1.000000   0.607298   \n",
       "agea_gndr     -0.127598 -0.060063  0.640597  0.741659    0.607298   1.000000   \n",
       "agea_sclmeet   0.454794  0.123117  0.030442  0.756282    0.694645   0.574744   \n",
       "happy_gndr     0.113899  0.080131  0.807616 -0.010638    0.266550   0.492776   \n",
       "happy_sclmeet  0.811592  0.308633 -0.001063 -0.168050    0.202723  -0.120401   \n",
       "\n",
       "               agea_sclmeet  happy_gndr  happy_sclmeet  \n",
       "year              -0.012521   -0.008215      -0.029354  \n",
       "tvtot              0.173123   -0.055287      -0.125004  \n",
       "ppltrst            0.049429    0.107068       0.218143  \n",
       "pplfair            0.072515    0.161255       0.203492  \n",
       "pplhlp             0.084799    0.159035       0.177702  \n",
       "happy              0.073647    0.542478       0.692849  \n",
       "sclmeet            0.454794    0.113899       0.811592  \n",
       "sclact             0.123117    0.080131       0.308633  \n",
       "gndr               0.030442    0.807616      -0.001063  \n",
       "agea               0.756282   -0.010638      -0.168050  \n",
       "agea_happy         0.694645    0.266550       0.202723  \n",
       "agea_gndr          0.574744    0.492776      -0.120401  \n",
       "agea_sclmeet       1.000000    0.065242       0.356296  \n",
       "happy_gndr         0.065242    1.000000       0.388697  \n",
       "happy_sclmeet      0.356296    0.388697       1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "correlation_matrix = X.corr()\n",
    "display(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.loc[:, ~X.columns.isin(['partner', 'cntry', 'idno', 'CH', 'CZ', 'DE', 'ES', 'NO', 'SE'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "59px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
